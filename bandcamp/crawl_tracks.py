import requests
import pandas as pd
from bs4 import BeautifulSoup
import time
import os

# æª”æ¡ˆåç¨±è¨­å®š
input_csv = "r_stevie_moore_albums_with_tracks.csv"
original_csv = "r_stevie_moore_albums_final.csv"
delay = 1.0  # æ¯æ¬¡æŠ“å–é–“éš”ç§’æ•¸ï¼Œå¯ä¾æƒ…æ³èª¿æ•´

# å˜—è©¦è®€å–ä¹‹å‰æŠ“åˆ°ä¸€åŠçš„æª”æ¡ˆï¼Œå¦å‰‡å°±å¾åŸå§‹æ¸…å–®é–‹å§‹
if os.path.exists(input_csv):
    print(f"ğŸ”„ å¾å·²å­˜åœ¨çš„æª”æ¡ˆç¹¼çºŒï¼š{input_csv}")
    df = pd.read_csv(input_csv)
else:
    print(f"ğŸ“¥ å¾åŸå§‹å°ˆè¼¯æ¸…å–®é–‹å§‹ï¼š{original_csv}")
    df = pd.read_csv(original_csv)
    df["Track Count"] = None  # åŠ ä¸Šæ¬„ä½

# é–‹å§‹æŠ“å–æ­Œæ›²æ•¸
for i, row in df.iterrows():
    if pd.notna(row.get("Track Count")):
        print(f"[{i+1}/{len(df)}] âœ… å·²æŠ“éï¼Œç•¥éï¼š{row['Title']}")
        continue

    url = row["URL"]
    print(f"[{i+1}/{len(df)}] æŠ“å–ï¼š{url}")
    try:
        res = requests.get(url, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        tracks = soup.select("tr.track_row_view")  # âœ… æ­£ç¢ºé¸æ“‡æ­Œæ›²åˆ—
        df.at[i, "Track Count"] = len(tracks)
        print(f" â†’ æŠ“åˆ° {len(tracks)} é¦–æ­Œ")
    except Exception as e:
        print(f" âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        df.at[i, "Track Count"] = None

    # æ¯ç­†å¯«å…¥ä¸€æ¬¡
    df.to_csv(input_csv, index=False)
    time.sleep(delay)

print(f"\nâœ… å…¨éƒ¨å®Œæˆæˆ–å·²ç•¥éï¼Œæœ€çµ‚çµæœå·²å„²å­˜è‡³ï¼š{input_csv}")
